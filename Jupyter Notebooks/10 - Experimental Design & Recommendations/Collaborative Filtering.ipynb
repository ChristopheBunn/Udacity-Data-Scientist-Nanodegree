{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations with MovieTweetings: Collaborative Filtering\n",
    "\n",
    "One of the most popular methods for making recommendations is **collaborative filtering**.  In collaborative filtering, you are using the collaboration of user-item recommendations to assist in making new recommendations.  \n",
    "\n",
    "There are two main methods of performing collaborative filtering:\n",
    "\n",
    "1. **Neighborhood-Based Collaborative Filtering**, which is based on the idea that we can either correlate items that are similar to provide recommendations or we can correlate users to one another to provide recommendations.\n",
    "\n",
    "2. **Model Based Collaborative Filtering**, which is based on the idea that we can use machine learning and other mathematical models to understand the relationships that exist amongst items and users to predict ratings and provide ratings.\n",
    "\n",
    "\n",
    "In this notebook, you will be working on performing **neighborhood-based collaborative filtering**.  There are two main methods for performing collaborative filtering:\n",
    "\n",
    "1. **User-based collaborative filtering:** In this type of recommendation, users related to the user you would like to make recommendations for are used to create a recommendation.\n",
    "\n",
    "2. **Item-based collaborative filtering:** In this type of recommendation, first you need to find the items that are most related to each other item (based on similar ratings).  Then you can use the ratings of an individual on those similar items to understand if a user will like the new item.\n",
    "\n",
    "In this notebook you will be implementing **user-based collaborative filtering**.  However, it is easy to extend this approach to make recommendations using **item-based collaborative filtering**.  First, let's read in our data and necessary libraries.\n",
    "\n",
    "**NOTE**: Because of the size of the datasets, some of your code cells here will take a while to execute, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id                                              movie  \\\n",
      "0         8      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
      "1        10                La sortie des usines Lumière (1895)   \n",
      "2        12                      The Arrival of a Train (1896)   \n",
      "3        25  The Oxford and Cambridge University Boat Race ...   \n",
      "4        91                         Le manoir du diable (1896)   \n",
      "\n",
      "               genre  date  1800's  1900's  2000's  History  News  Horror  \\\n",
      "0  Documentary|Short  1894       1       0       0        0     0       0   \n",
      "1  Documentary|Short  1895       1       0       0        0     0       0   \n",
      "2  Documentary|Short  1896       1       0       0        0     0       0   \n",
      "3                NaN  1895       1       0       0        0     0       0   \n",
      "4       Short|Horror  1896       1       0       0        0     0       1   \n",
      "\n",
      "     ...     Fantasy  Romance  Game-Show  Action  Documentary  Animation  \\\n",
      "0    ...           0        0          0       0            1          0   \n",
      "1    ...           0        0          0       0            1          0   \n",
      "2    ...           0        0          0       0            1          0   \n",
      "3    ...           0        0          0       0            0          0   \n",
      "4    ...           0        0          0       0            0          0   \n",
      "\n",
      "   Comedy  Short  Western  Thriller  \n",
      "0       0      1        0         0  \n",
      "1       0      1        0         0  \n",
      "2       0      1        0         0  \n",
      "3       0      0        0         0  \n",
      "4       0      1        0         0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "0        1     68646      10  1381620027  2013-10-12 23:20:27        0   \n",
      "1        1    113277      10  1379466669  2013-09-18 01:11:09        0   \n",
      "2        2    422720       8  1412178746  2014-10-01 15:52:26        0   \n",
      "3        2    454876       8  1394818630  2014-03-14 17:37:10        0   \n",
      "4        2    790636       7  1389963947  2014-01-17 13:05:47        0   \n",
      "\n",
      "   month_2  month_3  month_4  month_5    ...      month_9  month_10  month_11  \\\n",
      "0        0        0        0        0    ...            0         1         0   \n",
      "1        0        0        0        0    ...            0         0         0   \n",
      "2        0        0        0        0    ...            0         1         0   \n",
      "3        0        0        0        0    ...            0         0         0   \n",
      "4        0        0        0        0    ...            0         0         0   \n",
      "\n",
      "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
      "0         0          1          0          0          0          0          0  \n",
      "1         0          1          0          0          0          0          0  \n",
      "2         0          0          1          0          0          0          0  \n",
      "3         0          0          1          0          0          0          0  \n",
      "4         0          0          1          0          0          0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tests as t\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import HTML\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('movies_clean.csv')\n",
    "reviews = pd.read_csv('reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "print(movies[:5])\n",
    "print()\n",
    "print(reviews[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Similarity\n",
    "\n",
    "When using **neighborhood** based collaborative filtering, it is important to understand how to measure the similarity of users or items to one another.  \n",
    "\n",
    "There are a number of ways in which we might measure the similarity between two vectors (which might be two users or two items).  In this notebook, we will look specifically at two measures used to compare vectors:\n",
    "\n",
    "* **Pearson's correlation coefficient**\n",
    "\n",
    "Pearson's correlation coefficient is a measure of the strength and direction of a linear relationship. The value for this coefficient is a value between -1 and 1 where -1 indicates a strong, negative linear relationship and 1 indicates a strong, positive linear relationship. \n",
    "\n",
    "If we have two vectors x and y, we can define the correlation between the vectors as:\n",
    "\n",
    "\n",
    "$$CORR(x, y) = \\frac{\\text{COV}(x, y)}{\\text{STDEV}(x)\\text{ }\\text{STDEV}(y)}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\text{STDEV}(x) = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\text{COV}(x, y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "where n is the length of the vector, which must be the same for both x and y and $\\bar{x}$ is the mean of the observations in the vector.  \n",
    "\n",
    "We can use the correlation coefficient to indicate how alike two vectors are to one another, where the closer to 1 the coefficient, the more alike the vectors are to one another.  There are some potential downsides to using this metric as a measure of similarity.  You will see some of these throughout this workbook.\n",
    "\n",
    "\n",
    "* **Euclidean distance**\n",
    "\n",
    "Euclidean distance is a measure of the straightline distance from one vector to another.  Because this is a measure of distance, larger values are an indication that two vectors are different from one another (which is different than Pearson's correlation coefficient).\n",
    "\n",
    "Specifically, the euclidean distance between two vectors x and y is measured as:\n",
    "\n",
    "$$ \\text{EUCL}(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "Different from the correlation coefficient, no scaling is performed in the denominator.  Therefore, you need to make sure all of your data are on the same scale when using this metric.\n",
    "\n",
    "**Note:** Because measuring similarity is often based on looking at the distance between vectors, it is important in these cases to scale your data or to have all data be in the same scale.  If some measures are on a 5 point scale, while others are on a 100 point scale, you are likely to have non-optimal results due to the difference in variability of your features.  In this case, we will not need to scale data because they are all on a 10 point scale, but it is always something to keep in mind!\n",
    "\n",
    "------------\n",
    "\n",
    "### User-Item Matrix\n",
    "\n",
    "In order to calculate the similarities, it is common to put values in a matrix.  In this matrix, users are identified by each row, and items are represented by columns.  \n",
    "\n",
    "\n",
    "![alt text](images/userxitem.png \"User Item Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above matrix, you can see that **User 1** and **User 2** both used **Item 1**, and **User 2**, **User 3**, and **User 4** all used **Item 2**.  However, there are also a large number of missing values in the matrix for users who haven't used a particular item.  A matrix with many missing values (like the one above) is considered **sparse**.\n",
    "\n",
    "Our first goal for this notebook is to create the above matrix with the **reviews** dataset.  However, instead of 1 values in each cell, you should have the actual rating.  \n",
    "\n",
    "The users will indicate the rows, and the movies will exist across the columns. To create the user-item matrix, we only need the first three columns of the **reviews** dataframe, which you can see by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113277</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>422720</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>454876</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>790636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1     68646      10\n",
       "1        1    113277      10\n",
       "2        2    422720       8\n",
       "3        2    454876       8\n",
       "4        2    790636       7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the User-Item Matrix\n",
    "\n",
    "In order to create the user-items matrix (like the one above), I personally started by using a [pivot table](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html). \n",
    "\n",
    "However, I quickly ran into a memory error (a common theme throughout this notebook).  I will help you navigate around many of the errors I had, and achieve useful collaborative filtering results! \n",
    "\n",
    "_____\n",
    "\n",
    "`1.` Create a matrix where the users are the rows, the movies are the columns, and the ratings exist in each cell, or a NaN exists in cells where a user hasn't rated a particular movie. If you get a memory error (like I did), [this link here](https://stackoverflow.com/questions/39648991/pandas-dataframe-pivot-memory-error) might help you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>25</th>\n",
       "      <th>91</th>\n",
       "      <th>417</th>\n",
       "      <th>439</th>\n",
       "      <th>443</th>\n",
       "      <th>628</th>\n",
       "      <th>833</th>\n",
       "      <th>...</th>\n",
       "      <th>8144778</th>\n",
       "      <th>8144868</th>\n",
       "      <th>8206708</th>\n",
       "      <th>8289196</th>\n",
       "      <th>8324578</th>\n",
       "      <th>8335880</th>\n",
       "      <th>8342748</th>\n",
       "      <th>8342946</th>\n",
       "      <th>8402090</th>\n",
       "      <th>8439854</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  8        10       12       25       91       417      439      \\\n",
       "user_id                                                                   \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "movie_id  443      628      833       ...     8144778  8144868  8206708  \\\n",
       "user_id                               ...                                 \n",
       "1             NaN      NaN      NaN   ...         NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN   ...         NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN   ...         NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN   ...         NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN   ...         NaN      NaN      NaN   \n",
       "\n",
       "movie_id  8289196  8324578  8335880  8342748  8342946  8402090  8439854  \n",
       "user_id                                                                  \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 31245 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create user-by-item matrix\n",
    "#user_by_movie = pd.pivot_table(user_items, values='rating', index='user_id', columns='movie_id')\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "user_by_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_1_movies = \n",
      "movie_id\n",
      "68646     10.0\n",
      "113277    10.0\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "user_1_movies_index = \n",
      "Int64Index([68646, 113277], dtype='int64', name='movie_id')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 68646, 113277])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_1_movies = user_by_movie.loc[1][user_by_movie.loc[1].isnull() == False]\n",
    "print('user_1_movies = \\n{}\\n'.format(user_1_movies))\n",
    "user_1_movies_index = user_1_movies.index\n",
    "print('user_1_movies_index = \\n{}\\n'.format(user_1_movies_index))\n",
    "user_1_movies_index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your results below to make sure your matrix is ready for the upcoming sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you are all set! Proceed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert movies.shape[0] == user_by_movie.shape[1], \\\n",
    "       \"Oh no! Your matrix should have {} columns, and yours has {}!\".format(\n",
    "           movies.shape[0], user_by_movie.shape[1])\n",
    "assert reviews.user_id.nunique() == user_by_movie.shape[0], \\\n",
    "       \"Oh no! Your matrix should have {} rows, and yours has {}!\".format(\n",
    "           reviews.user_id.nunique(), user_by_movie.shape[0])\n",
    "print(\"Looks like you are all set! Proceed!\")\n",
    "HTML('<img src=\"images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have a matrix of users by movies, use this matrix to create a dictionary where the key is each user and the value is an array of the movies each user has rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 68646, 113277]),\n",
       " 2: array([ 422720,  454876,  790636,  816711, 1091191, 1103275, 1322269,\n",
       "        1390411, 1398426, 1431045, 1433811, 1454468, 1535109, 1675434,\n",
       "        1798709, 2017038, 2024544, 2294629, 2361509, 2381249, 2726560,\n",
       "        2883512, 3079380]),\n",
       " 3: array([1790864, 2170439, 2203939]),\n",
       " 4: array([1300854]),\n",
       " 5: array([ 54953, 120863])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with users and corresponding movies seen\n",
    "\n",
    "def movies_watched(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    movies - an array of movies the user has watched\n",
    "    '''\n",
    "    movies = user_by_movie.loc[user_id][user_by_movie.loc[user_id].isnull() == False].index.values\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "def create_user_movie_dict():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    Creates the movies_seen dictionary\n",
    "    '''\n",
    "    num_users = user_by_movie.shape[0]\n",
    "    movies_seen = dict()\n",
    "    \n",
    "    for id in range(1, num_users + 1):\n",
    "        movies_seen[id] = movies_watched(id)\n",
    "    \n",
    "    return movies_seen\n",
    "\n",
    "\n",
    "# Use your function to return dictionary\n",
    "movies_seen = create_user_movie_dict()\n",
    "dict(list(movies_seen.items())[:5])    # similar to DataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` If a user hasn't rated more than 2 movies, we consider these users \"too new\".  Create a new dictionary that only contains users who have rated more than 2 movies.  This dictionary will be used for all the final steps of this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: array([ 422720,  454876,  790636,  816711, 1091191, 1103275, 1322269,\n",
       "        1390411, 1398426, 1431045, 1433811, 1454468, 1535109, 1675434,\n",
       "        1798709, 2017038, 2024544, 2294629, 2361509, 2381249, 2726560,\n",
       "        2883512, 3079380]),\n",
       " 3: array([1790864, 2170439, 2203939]),\n",
       " 7: array([1764234, 1790885, 2053463]),\n",
       " 8: array([ 385002, 1220198, 1462900, 1512685, 1631707, 1986994, 1999995]),\n",
       " 9: array([ 65207, 363163, 985699])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove individuals who have watched 2 or fewer movies - don't have enough data to make recs\n",
    "\n",
    "def create_movies_to_analyze(movies_seen, lower_bound=2):\n",
    "    '''\n",
    "    INPUT:  \n",
    "    movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    lower_bound - (an int) a user must have more movies seen than the lower bound\n",
    "                           to be added to the movies_to_analyze dictionary\n",
    "\n",
    "    OUTPUT: \n",
    "    movies_to_analyze - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    The movies_seen and movies_to_analyze dictionaries should be the same except that the output dictionary has removed \n",
    "    \n",
    "    '''\n",
    "    movies_to_analyze = dict()\n",
    "    \n",
    "    for usr, mov_list in movies_seen.items():\n",
    "        if len(mov_list) > lower_bound:\n",
    "            movies_to_analyze[usr] = mov_list\n",
    "    \n",
    "    return movies_to_analyze\n",
    "\n",
    "\n",
    "# Use your function to return your updated dictionary\n",
    "movies_to_analyze = create_movies_to_analyze(movies_seen)\n",
    "dict(list(movies_to_analyze.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you are good to go!\n"
     ]
    }
   ],
   "source": [
    "# Run the tests below to check that your movies_to_analyze matches the solution\n",
    "assert len(movies_to_analyze) == 23512, \"Oops!  It doesn't look like your dictionary has the right number of individuals.\"\n",
    "assert len(movies_to_analyze[2]) == 23, \"Oops!  User 2 didn't match the number of movies we thought they would have.\"\n",
    "assert len(movies_to_analyze[7])  == 3, \"Oops!  User 7 didn't match the number of movies we thought they would have.\"\n",
    "print(\"If this is all you see, you are good to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating User Similarities\n",
    "\n",
    "Now that you have set up the **movies_to_analyze** dictionary, it is time to take a closer look at the similarities between users.  Below is the pseudocode for how I thought about determining the similarity between users:\n",
    "\n",
    "```\n",
    "for user1 in movies_to_analyze\n",
    "    for user2 in movies_to_analyze\n",
    "        see how many movies match between the two users\n",
    "        if more than two movies in common\n",
    "            pull the overlapping movies\n",
    "            compute the distance/similarity metric between ratings on the same movies for the two users\n",
    "            store the users and the distance metric\n",
    "```\n",
    "\n",
    "However, this took a very long time to run, and other methods of performing these operations did not fit on the workspace memory!\n",
    "\n",
    "Therefore, rather than creating a dataframe with all possible pairings of users in our data, your task for this question is to look at a few specific examples of the correlation between ratings given by two users.  For this question consider you want to compute the [correlation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) between users.\n",
    "\n",
    "`4.` Using the **movies_to_analyze** dictionary and **user_by_movie** dataframe, create a function that computes the correlation between the ratings of similar movies for two users.  Then use your function to compare your results to ours using the tests below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_2 (23) =\n",
      "[422720, 454876, 790636, 816711, 1091191, 1103275, 1322269, 1390411, 1398426, 1431045]\n",
      "\n",
      "movies_66 (267) = \n",
      "[33467, 33870, 36775, 37008, 37017, 38057, 38854, 39757, 40202, 40897]\n",
      "\n",
      "movies_2_66 (3) =\n",
      "[1454468, 1798709, 2883512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just playing around, figuring out how to extract the data...\n",
    "\n",
    "movies_2 = list(movies_to_analyze.get(2))\n",
    "movies_66 = list(movies_to_analyze.get(66))\n",
    "print('movies_2 ({}) =\\n{}\\n\\nmovies_66 ({}) = \\n{}\\n'.format(\n",
    "    len(movies_2), movies_2[:10], len(movies_66), movies_66[:10]))\n",
    "movies_2_66 = list(np.intersect1d(movies_2, movies_66))\n",
    "print('movies_2_66 ({}) =\\n{}\\n'.format(len(movies_2_66), movies_2_66[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>2</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454468</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798709</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883512</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id     2    66\n",
       "movie_id           \n",
       "1454468    8.0  6.0\n",
       "1798709   10.0  9.0\n",
       "2883512    8.0  8.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_2_66_by_movie = user_by_movie.loc[[2, 66]][movies_2_66]\n",
    "users_2_66_by_movie.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>2</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.755929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id        2         66\n",
       "user_id                    \n",
       "2        1.000000  0.755929\n",
       "66       0.755929  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_2_66_by_movie.transpose().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the correlation between the matching ratings between the two users\n",
    "    '''\n",
    "    movies_1_and_2 = list(np.intersect1d(movies_to_analyze[user1], movies_to_analyze[user2]))\n",
    "    movies_1_and_2_df = user_by_movie.loc[[user1, user2], movies_1_and_2]\n",
    "    \n",
    "    corr = movies_1_and_2_df.transpose().corr().iloc[0, 1]\n",
    "  \n",
    "    return corr #return the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_2_2 =  1.0\n",
      "corr_2_66 =  0.76\n",
      "corr_2_104 =  nan\n",
      "If this is all you see, then it looks like your function passed all of our tests!\n"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "\n",
    "corr_2_2 = compute_correlation(2,2)\n",
    "print('corr_2_2 = ', corr_2_2)\n",
    "assert corr_2_2 == 1.0, \"Oops!  The correlation between a user and itself should be 1.0.\"\n",
    "\n",
    "corr_2_66 = round(compute_correlation(2,66), 2)\n",
    "print('corr_2_66 = ', corr_2_66)\n",
    "assert corr_2_66 == 0.76, \"Oops!  The correlation between user 2 and 66 should be about 0.76.\"\n",
    "\n",
    "corr_2_104 = compute_correlation(2,104)\n",
    "print('corr_2_104 = ', corr_2_104)\n",
    "assert np.isnan(corr_2_104), \"Oops!  The correlation between user 2 and 104 should be a NaN.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the NaN's?\n",
    "\n",
    "If the function you wrote passed all of the tests, then you have correctly set up your function to calculate the correlation between any two users.  \n",
    "\n",
    "`5.` But one question is, why are we still obtaining **NaN** values?  As you can see in the code cell above, users 2 and 104 have a correlation of **NaN**. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think and write your ideas here about why these NaNs exist, and use the cells below to do some coding to validate your thoughts. You can check other pairs of users and see that there are actually many NaNs in our data - 2,526,710 of them in fact. These NaN's ultimately make the correlation coefficient a less than optimal measure of similarity between two users.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[454876, 816711, 1454468, 1535109]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which movies did both user 2 and user 104 see?\n",
    "movies_2_104 = list(np.intersect1d(movies_to_analyze[2], movies_to_analyze[104]))\n",
    "movies_2_104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>454876</th>\n",
       "      <th>816711</th>\n",
       "      <th>1454468</th>\n",
       "      <th>1535109</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  454876   816711   1454468  1535109\n",
       "user_id                                     \n",
       "2             8.0      8.0      8.0      8.0\n",
       "104           9.0      7.0      7.0      9.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the ratings for each user for those movies?\n",
    "user_by_movie.loc[[2, 104], movies_2_104]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` Because the correlation coefficient proved to be less than optimal for relating user ratings to one another, we could instead calculate the euclidean distance between the ratings.  I found [this post](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) particularly helpful when I was setting up my function.  This function should be very similar to your previous function.  When you feel confident with your function, test it against our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mov_2 =\n",
      "\n",
      "movie_id\n",
      "1454468     8.0\n",
      "1798709    10.0\n",
      "2883512     8.0\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "mov_66 =\n",
      "\n",
      "movie_id\n",
      "1454468    6.0\n",
      "1798709    9.0\n",
      "2883512    8.0\n",
      "Name: 66, dtype: float64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numexpr/cpuinfo.py:42: UserWarning: [Errno 12] Cannot allocate memory\n",
      "  warnings.warn(str(e), UserWarning, stacklevel=stacklevel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euc_dist_2_66 =  2.24\n"
     ]
    }
   ],
   "source": [
    "# Just playing around, to better visualize the data\n",
    "\n",
    "mov_2 = user_by_movie.loc[2, movies_2_66]\n",
    "print('mov_2 =\\n\\n{}\\n'.format(mov_2))\n",
    "mov_66 = user_by_movie.loc[66, movies_2_66]\n",
    "print('mov_66 =\\n\\n{}\\n'.format(mov_66))\n",
    "euc_dist_2_66 = np.linalg.norm(mov_2 - mov_66)\n",
    "print('euc_dist_2_66 = ', round(euc_dist_2_66, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_dist(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the euclidean distance between user1 and user2\n",
    "    '''\n",
    "    movies_1_and_2 = list(np.intersect1d(movies_to_analyze[user1], movies_to_analyze[user2]))\n",
    "    movies_1_df = user_by_movie.loc[user1, movies_1_and_2]\n",
    "    movies_2_df = user_by_movie.loc[user2, movies_1_and_2]\n",
    "    \n",
    "    dist = np.linalg.norm(movies_1_df - movies_2_df)\n",
    "   \n",
    "    return dist #return the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>eucl_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2.236068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.385165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2.828427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user1  user2  eucl_dist\n",
       "0      2      2   0.000000\n",
       "1      2     66   2.236068\n",
       "2      2     90   5.385165\n",
       "3      2     99   2.828427\n",
       "4      2    104   2.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in solution euclidean distances\n",
    "import pickle\n",
    "df_dists = pd.read_pickle(\"data/Term2/recommendations/lesson1/data/dists.p\")\n",
    "df_dists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euc_dist_2_2 = 0.0\n",
      "\n",
      "euc_dist_2_66 = 2.24\n",
      "\n",
      "euc_dist_2_104 = 2.0\n",
      "\n",
      "If this is all you see, then it looks like your function passed all of our tests!\n"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "\n",
    "euc_dist_2_2 = compute_euclidean_dist(2,2)\n",
    "print('euc_dist_2_2 = {}\\n'.format(euc_dist_2_2))\n",
    "assert euc_dist_2_2 == df_dists.query(\"user1 == 2 and user2 == 2\")['eucl_dist'][0], \\\n",
    "       \"Oops! The distance between a user and itself should be 0.0.\"\n",
    "\n",
    "euc_dist_2_66 = round(compute_euclidean_dist(2,66), 2)\n",
    "print('euc_dist_2_66 = {}\\n'.format(euc_dist_2_66))\n",
    "assert euc_dist_2_66 == round(df_dists.query(\"user1 == 2 and user2 == 66\")['eucl_dist'][1], 2), \\\n",
    "       \"Oops!  The distance between user 2 and 66 should be about 2.24.\"\n",
    "\n",
    "euc_dist_2_104 = compute_euclidean_dist(2,104)\n",
    "print('euc_dist_2_104 = {}\\n'.format(euc_dist_2_104))\n",
    "assert np.isnan(euc_dist_2_104) == np.isnan(df_dists.query(\"user1 == 2 and user2 == 104\")['eucl_dist'][4]), \\\n",
    "       \"Oops!  The distance between user 2 and 104 should be 2.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Nearest Neighbors to Make Recommendations\n",
    "\n",
    "In the previous question, you read in **df_dists**. Therefore, you have a measure of distance between each user and every other user. This dataframe holds every possible pairing of users, as well as the corresponding euclidean distance.\n",
    "\n",
    "Because of the **NaN** values that exist within the correlations of the matching ratings for many pairs of users, as we discussed above, we will proceed using **df_dists**. You will want to find the users that are 'nearest' each user.  Then you will want to find the movies the closest neighbors have liked to recommend to each user.\n",
    "\n",
    "I made use of the following objects:\n",
    "\n",
    "* df_dists (to obtain the neighbors)\n",
    "* user_items (to obtain the movies the neighbors and users have rated)\n",
    "* movies (to obtain the names of the movies)\n",
    "\n",
    "`7.` Complete the functions below, which allow you to find the recommendations for any user.  There are five functions which you will need:\n",
    "\n",
    "* **find_closest_neighbors** - this returns a list of user_ids from closest neighbor to farthest neighbor using euclidean distance\n",
    "\n",
    "\n",
    "* **movies_liked** - returns an array of movie_ids\n",
    "\n",
    "\n",
    "* **movie_names** - takes the output of movies_liked and returns a list of movie names associated with the movie_ids\n",
    "\n",
    "\n",
    "* **make_recommendations** - takes a user id and goes through closest neighbors to return a list of movie names as recommendations\n",
    "\n",
    "\n",
    "* **all_recommendations** = loops through every user and returns a dictionary of with the key as a user_id and the value as a list of movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 closest to 66:\n",
      "\n",
      "       user2  eucl_dist\n",
      "34506  33854        0.0\n",
      "34972  37869        0.0\n",
      "31927  12075        0.0\n",
      "32076  13459        0.0\n",
      "31627   9466        0.0\n",
      "\n",
      "5 furthest from 66:\n",
      "\n",
      "       user2  eucl_dist\n",
      "31739  10481  17.000000\n",
      "30902   3425  17.146428\n",
      "33576  26173  17.175564\n",
      "33067  21695  19.974984\n",
      "36883  53966  20.174241\n"
     ]
    }
   ],
   "source": [
    "# Just playing around...\n",
    "\n",
    "distances_66 = df_dists[(df_dists['user1'] == 66) & (df_dists['user2'] != 66)][['user2', 'eucl_dist']]\n",
    "distances_66.sort_values('eucl_dist', ascending=True, inplace=True)\n",
    "print('5 closest to 66:\\n\\n{}\\n'.format(distances_66[:5]))\n",
    "print('5 furthest from 66:\\n\\n{}'.format(distances_66[-6:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_neighbors(user):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) the user_id of the individual you want to find the closest users\n",
    "    OUTPUT:\n",
    "        closest_neighbors - an array of the id's of the users sorted from closest to farthest away\n",
    "    '''\n",
    "    # I treated ties as arbitrary and just kept whichever was easiest to keep using the head method\n",
    "    # You might choose to do something less hand wavy - order the neighbors\n",
    "    closest_neighbors = df_dists[(df_dists['user1'] == user) & (df_dists['user2'] != user)][['user2', 'eucl_dist']]\n",
    "    closest_neighbors.sort_values(by='eucl_dist', ascending=True, inplace=True)\n",
    "    \n",
    "    return closest_neighbors['user2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34506    33854\n",
       "34972    37869\n",
       "31927    12075\n",
       "32076    13459\n",
       "31627     9466\n",
       "Name: user2, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and checking ...\n",
    "\n",
    "find_closest_neighbors(66).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>33467</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>33870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>36775</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>37008</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>37017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id  rating\n",
       "559     33467       8\n",
       "560     33870       9\n",
       "561     36775       9\n",
       "562     37008       7\n",
       "563     37017       7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and playing ...\n",
    "\n",
    "movies_66_7 = reviews[(reviews['user_id'] == 66) & (reviews['rating'] >= 7)][['movie_id', 'rating']]\n",
    "movies_66_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies_liked(user_id, min_rating=7):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    min_rating - the minimum rating considered while still a movie is still a \"like\" and not a \"dislike\"\n",
    "    OUTPUT:\n",
    "    movies_liked - an array of movies the user has watched and liked\n",
    "    '''\n",
    "    movies_liked = reviews[(reviews['user_id'] == user_id) & (reviews['rating'] >= min_rating)]['movie_id']\n",
    "    # The solution gives:\n",
    "    # movies_liked = np.array(user_items.query('user_id == @user_id and rating > (@min_rating -1)')['movie_id'])\n",
    "  \n",
    "    return movies_liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559    33467\n",
       "560    33870\n",
       "561    36775\n",
       "562    37008\n",
       "563    37017\n",
       "Name: movie_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and checking ...\n",
    "\n",
    "movies_liked(66, min_rating=5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Edison Kinetoscopic Record of a Sneeze (1894)\n",
       "1                  La sortie des usines Lumière (1895)\n",
       "2                        The Arrival of a Train (1896)\n",
       "3    The Oxford and Cambridge University Boat Race ...\n",
       "4                           Le manoir du diable (1896)\n",
       "Name: movie, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and playing ...\n",
    "\n",
    "movies[movies['movie_id'].isin([8, 10, 12, 25, 91])]['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_names(movie_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_ids - a list of movie_ids\n",
    "    OUTPUT\n",
    "    movies - a list of movie names associated with the movie_ids\n",
    "    \n",
    "    '''\n",
    "    movie_lst = movies[movies['movie_id'].isin(movie_ids)]['movie']\n",
    "\n",
    "    return movie_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Edison Kinetoscopic Record of a Sneeze (1894)\n",
       "1                  La sortie des usines Lumière (1895)\n",
       "2                        The Arrival of a Train (1896)\n",
       "3    The Oxford and Cambridge University Boat Race ...\n",
       "4                           Le manoir du diable (1896)\n",
       "Name: movie, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and checking ...\n",
    "\n",
    "movie_names([8, 10, 12, 25, 91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(user, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) a user_id of the individual you want to make recommendations for\n",
    "        num_recs - (int) number of movies to return\n",
    "    OUTPUT:\n",
    "        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n",
    "                          otherwise return the total number of recommendations available for the \"user\"\n",
    "                          which may just be an empty list\n",
    "    '''\n",
    "    closest_neighbors = find_closest_neighbors(user)\n",
    "    movies_already_seen = movies_watched(user)\n",
    "    recs = np.array([])\n",
    "    \n",
    "    for neighbor in closest_neighbors:\n",
    "        movies_liked_by_neighbor = movies_liked(neighbor, min_rating=8)\n",
    "        \n",
    "        # Add the neighbor's movies, except those already seen by the user\n",
    "        neighbor_recs = np.setdiff1d(movies_liked_by_neighbor, movies_already_seen, assume_unique=True)\n",
    "        recs = np.unique(np.concatenate([neighbor_recs, recs], axis=0))\n",
    "        \n",
    "        if len(recs) >= num_recs:\n",
    "            recs = recs[:num_recs]\n",
    "            break\n",
    "    \n",
    "    recommendations = list(movie_names(recs))\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once Upon a Time in America (1984)',\n",
       " 'Donnie Brasco (1997)',\n",
       " 'Godzilla (2014)',\n",
       " 'The Lego Movie (2014)',\n",
       " 'Despicable Me 2 (2013)',\n",
       " 'Captain America: The Winter Soldier (2014)',\n",
       " 'Trance (2013)',\n",
       " 'Guardians of the Galaxy (2014)',\n",
       " 'Dawn of the Planet of the Apes (2014)',\n",
       " 'Muppets Most Wanted (2014)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and checking ...\n",
    "\n",
    "make_recommendations(66, num_recs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "def all_recommendations(num_recs=10):\n",
    "    '''\n",
    "    INPUT \n",
    "        num_recs (int) the (max) number of recommendations for each user\n",
    "    OUTPUT\n",
    "        all_recs - a dictionary where each key is a user_id and the value is an array of recommended movie titles\n",
    "    '''\n",
    "    # Make the recommendations for each user\n",
    "    all_users = df_dists['user1'].unique()\n",
    "    all_recs = dict()\n",
    "    pbar = ProgressBar()    # the code below runs forever!\n",
    "    \n",
    "    for user in pbar(all_users):\n",
    "        all_recs[user] = make_recommendations(user, num_recs)\n",
    "    \n",
    "    return all_recs\n",
    "\n",
    "all_recs = all_recommendations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_recs has 23512 elements\n",
      "\n",
      "\n",
      "user 2 movies:\n",
      "['His Majesty, the Scarecrow of Oz (1914)', 'Three Ages (1923)', 'The Navigator (1924)', 'Sherlock Jr. (1924)', 'The Thief of Bagdad (1924)', 'The Cocoanuts (1929)', 'Frau im Mond (1929)', 'The Green Hornet (1940)', 'The Mark of Zorro (1940)', 'Lifeboat (1944)']\n",
      "\n",
      "\n",
      "user 3 movies:\n",
      "['Basic Instinct (1992)', 'The Shawshank Redemption (1994)', 'The Hangover (2009)', 'Limitless (2011)', 'Inception (2010)', \"The King's Speech (2010)\", 'Love, Rosie (2014)', 'The Intouchables (2011)', 'American Hustle (2013)', 'Divergent (2014)']\n",
      "\n",
      "\n",
      "user 7 movies:\n",
      "['The Philadelphia Story (1940)', 'The Magnificent Ambersons (1942)', 'The Third Man (1949)', 'From Here to Eternity (1953)', 'Les vacances de Monsieur Hulot (1953)', 'Shichinin no samurai (1954)', 'The Night of the Hunter (1955)', 'The Searchers (1956)', 'Touch of Evil (1958)', 'The Magnificent Seven (1960)']\n",
      "\n",
      "\n",
      "user 8 movies:\n",
      "['Psycho (1960)', 'Jesus Christ Superstar (1973)', 'Monty Python and the Holy Grail (1975)', 'The Shining (1980)', 'Creepshow (1982)', 'Christine (1983)', 'A Nightmare on Elm Street (1984)', 'Hellraiser (1987)', 'RoboCop (1987)', \"Child's Play (1988)\"]\n",
      "\n",
      "\n",
      "user 9 movies:\n",
      "['Octopussy (1983)', 'Trading Places (1983)', 'Christmas Vacation (1989)', 'Ghost (1990)', 'Edge of Honor (1991)', 'Fargo (1996)', 'The Bank Job (2008)', 'Snatch. (2000)', 'Dawn of the Dead (2004)', 'The Heartbreak Kid (2007)']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('all_recs has {} elements\\n\\n'.format(len(all_recs)))\n",
    "for user, movie in list(all_recs.items())[:5]:\n",
    "    print('user {} movies:\\n{}\\n\\n'.format(user, movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_recs_sol has 23512 elements\n",
      "\n",
      "\n",
      "user 2 movies:\n",
      "['Philadelphia (1993)', 'Training Day (2001)', 'About Schmidt (2002)', 'Insomnia (2002)', 'The United States of Leland (2003)', 'Shattered Glass (2003)', 'Man on Fire (2004)', 'Flipped (2010)', 'Silver Linings Playbook (2012)', 'Lawless (2012)', '50/50 (2011)', 'Crazy, Stupid, Love. (2011)', 'The Perks of Being a Wallflower (2012)', 'Before I Go to Sleep (2014)', 'Zero Dark Thirty (2012)', 'American Hustle (2013)', 'Django Unchained (2012)', 'Side Effects (2013)', 'Gone Girl (2014)', 'Enough Said (2013)', 'Nightcrawler (2014)']\n",
      "\n",
      "\n",
      "user 3 movies:\n",
      "['Basic Instinct (1992)', 'The Shawshank Redemption (1994)', 'The Wedding Ringer (2015)', 'Life as We Know It (2010)', 'The Hangover (2009)', 'Limitless (2011)', 'The Great Gatsby (2013)', 'This Is Where I Leave You (2014)', 'Inception (2010)', \"The King's Speech (2010)\", 'Love, Rosie (2014)', 'Now You See Me (2013)', 'The Intouchables (2011)', 'Safe Haven (2013)', 'Before I Go to Sleep (2014)', 'American Hustle (2013)', 'Passion (2012)', 'Divergent (2014)', 'The Judge (2014)', 'The Hangover Part III (2013)', 'Non-Stop (2014)', 'The Imitation Game (2014)', 'Dumb and Dumber To (2014)', 'St. Vincent (2014)', 'Into the Woods (2014)', 'Gone Girl (2014)', 'Focus (2015)', 'Walk of Shame (2014)', 'The Fault in Our Stars (2014)', 'Insurgent (2015)', 'The Theory of Everything (2014)', 'Spy (2015)', 'Sadece Sen (2014)', 'Hidden Figures (2016)']\n",
      "\n",
      "\n",
      "user 7 movies:\n",
      "['The Philadelphia Story (1940)', 'The Magnificent Ambersons (1942)', 'The Third Man (1949)', 'From Here to Eternity (1953)', 'Les vacances de Monsieur Hulot (1953)', 'Shichinin no samurai (1954)', 'The Night of the Hunter (1955)', 'The Searchers (1956)', 'Bonjour tristesse (1958)', 'Touch of Evil (1958)', 'The Magnificent Seven (1960)', 'The Spy Who Came in from the Cold (1965)', \"Rosemary's Baby (1968)\", \"L'armée des ombres (1969)\", 'Two-Lane Blacktop (1971)', 'The Godfather (1972)', 'Play It Again, Sam (1972)', \"Don't Look Now (1973)\", 'Mean Streets (1973)', 'Serpico (1973)', 'Young Frankenstein (1974)', 'Dog Day Afternoon (1975)', 'Novecento (1976)', 'Network (1976)', 'The Black Panther (1977)', 'Bad Timing (1980)', 'The Thing (1982)', 'The King of Comedy (1983)', 'Local Hero (1983)', 'Brazil (1985)', 'The Princess Bride (1987)', 'Another Woman (1988)', 'Cyrano de Bergerac (1990)', 'Manhattan Murder Mystery (1993)', 'The Last Seduction (1994)', 'Kingpin (1996)', 'Romeo + Juliet (1996)', 'Trees Lounge (1996)', 'My Name Is Joe (1998)', 'Trolösa (2000)', 'Pane e tulipani (2000)', 'De reis van Chihiro (2001)', 'Les triplettes de Belleville (2003)', 'The Secret Life of Walter Mitty (2013)', 'The Room (2003)', 'Lincoln (2012)', 'Wonder Woman (2017)', 'Scoop (2006)', 'Alan Partridge: Alpha Papa (2013)', 'Ex Machina (2015)', 'Hail, Caesar! (2016)', 'Ant-Man (2015)', 'La sconosciuta (2006)', 'Dallas Buyers Club (2013)', 'Jack Reacher (2012)', 'The Danish Girl (2015)', 'Interstellar (2014)', 'Suite française (2014)', 'The Hobbit: An Unexpected Journey (2012)', 'Love &amp; Mercy (2014)', 'Chega de Saudade (2007)', 'Argo (2012)', 'Silver Linings Playbook (2012)', 'Paddington (2014)', 'Free State of Jones (2016)', 'The Hobbit: The Desolation of Smaug (2013)', 'Lawless (2012)', 'Brave (2012)', 'Greenberg (2010)', 'Mistérios de Lisboa (2010)', 'Mademoiselle Chambon (2009)', 'Behind the Candelabra (2013)', 'Snabba cash (2010)', 'Iron Man 3 (2013)', 'El secreto de sus ojos (2009)', 'The Great Gatsby (2013)', 'The Infiltrator (2016)', 'Passengers (2016)', 'Darbareye Elly (2009)', 'Das letzte Schweigen (2010)', 'This Is Where I Leave You (2014)', 'Mad Max: Fury Road (2015)', 'Prisoners (2013)', 'It (2017)', 'Straight Outta Compton (2015)', 'Star Trek Into Darkness (2013)', 'Skeletons (2010)', 'Mientras duermes (2011)', 'Broken (2012)', 'Testament of Youth (2014)', 'Filth (2013)', 'Monsters University (2013)', 'Gravity (2013)', 'The Greatest Showman (2017)', 'What If (2013)', 'The Lego Movie (2014)', 'The Paperboy (2012)', 'Byzantium (2012)', 'Captain Phillips (2013)', 'Nostalgia de la luz (2010)', 'The Master (2012)', 'The Skeleton Twins (2014)', 'Warm Bodies (2013)', 'The Big Short (2015)', 'Only God Forgives (2013)', 'Amour (2012)', 'Frank (2014)', 'Kon-Tiki (2012)', 'Margin Call (2011)', 'Bleed for This (2016)', 'Lo imposible (2012)', 'Kiseki (2011)', 'À perdre la raison (2012)', 'The Revenant (2015)', 'Welcome to the Punch (2013)', 'La source des femmes (2011)', 'Despicable Me 2 (2013)', 'Bernie (2011)', 'Only Lovers Left Alive (2013)', 'La vida útil (2010)', 'The Way, Way Back (2013)', 'Oslo, 31. august (2011)', 'Arbitrage (2012)', 'Danny Collins (2015)', 'Wreck-It Ralph (2012)', 'Southpaw (2015)', 'Her (2013)', 'Gold (2016)', 'Gianni e le donne (2011)', 'The Place Beyond the Pines (2012)', 'Nebraska (2013)', 'Black Panther (2018)', 'Metro Manila (2013)', 'Django Unchained (2012)', \"You're Next (2011)\", 'Den skaldede frisør (2012)', 'Blancanieves (2012)', 'End of Watch (2012)', 'Blade Runner 2049 (2017)', 'To Rome with Love (2012)', 'Song of the Sea (2014)', 'The Sessions (2012)', 'The East (2013)', 'The Amazing Spider-Man 2 (2014)', 'The Edge of Seventeen (2016)', 'Spotlight (2015)', 'Flight (2012)', 'Good Vibrations (2012)', 'What Maisie Knew (2012)', 'Mud (2012)', 'The Look of Love (2013)', 'The Hunger Games: Catching Fire (2013)', 'Dans la maison (2012)', 'A Most Wanted Man (2014)', 'Rush (2013)', 'Begin Again (2013)', 'Pitch Perfect (2012)', 'Robot & Frank (2012)', 'Tower Block (2012)', 'Lore (2012)', 'Monsieur Lazhar (2011)', 'Guardians of the Galaxy (2014)', 'All Is Lost (2013)', 'Sightseers (2012)', '12 Years a Slave (2013)', 'Starlet (2012)', 'Inside Llewyn Davis (2013)', \"De rouille et d'os (2012)\", 'Eye in the Sky (2015)', 'Populaire (2012)', 'Steve Jobs (2015)', 'What Richard Did (2012)', 'Much Ado About Nothing (2012)', 'Dawn of the Planet of the Apes (2014)', 'Jagten (2012)', 'Mea Maxima Culpa: Silence in the House of God (2012)', 'Hacksaw Ridge (2016)', 'Searching for Sugar Man (2012)', 'The Queen of Versailles (2012)', 'The Mule (2014)', 'West of Memphis (2012)', 'Saving Mr. Banks (2013)', 'Maps to the Stars (2014)', 'The Kings of Summer (2013)', 'American Sniper (2014)', 'O som ao redor (2012)', 'About Time (2013)', 'Before Midnight (2013)', 'Kapringen (2012)', 'Calvary (2014)', 'Dear White People (2014)', 'Money Monster (2016)', 'I Give It a Year (2013)', 'Spider-Man: Homecoming (2017)', 'Fading Gigolo (2013)', 'Wadjda (2012)', 'The Raid 2: Berandal (2014)', 'Drinking Buddies (2013)', 'Gone Girl (2014)', 'Finding Dory (2016)', 'The Grand Budapest Hotel (2014)', \"La vie d'Adèle (2013)\", 'Frozen (2013)', 'In a World... (2013)', 'The Selfish Giant (2013)', 'Big Bad Wolves (2013)', 'The Gatekeepers (2012)', 'Enemy (2013)', 'Ma vie de Courgette (2016)', 'The Babadook (2014)', 'A Girl Walks Home Alone at Night (2014)', 'Fruitvale Station (2013)', 'Blue Jasmine (2013)', 'Frances Ha (2012)', 'Mississippi Grind (2015)', 'La grande bellezza (2013)', 'Stories We Tell (2012)', 'Short Term 12 (2013)', 'A Field in England (2013)', 'The Act of Killing (2012)', 'The Glass Castle (2017)', 'Spectre (2015)', 'Brooklyn (2015)', 'Nymphomaniac: Volume II (2013)', 'Life Itself (2014)', 'Enough Said (2013)', 'Le Week-End (2013)', 'Still Life (2013)', 'Mudbound (2017)', 'Predestination (2014)', 'Carol (2015)', 'The Heat (2013)', 'La Vénus à la fourrure (2013)', 'Philomena (2013)', 'Exhibition (2013)', 'Kvinden i buret (2013)', 'Clouds of Sils Maria (2014)', 'Il capitale umano (2013)', 'Get on Up (2014)', 'Mr. Turner (2014)', 'Star Wars: The Force Awakens (2015)', 'Bone Tomahawk (2015)', 'The Beatles: Eight Days a Week - The Touring Years (2016)', 'Birdman (2014)', 'Starred Up (2013)', 'Kaguyahime no monogatari (2013)', 'Hell or High Water (2016)', 'Whiplash (2014)', 'Love Is Strange (2014)', 'Midnight Special (2016)', 'Locke (2013)', 'Ida (2013)', 'The Salvation (2014)', 'Deux jours, une nuit (2014)', 'The One I Love (2014)', 'T2 Trainspotting (2017)', 'Phoenix (2014)', 'Annihilation (2018)', 'Kingsman: The Secret Service (2014)', 'Leviathan (2014)', 'Coherence (2013)', 'Amy (2015)', 'Wish I Was Here (2014)', 'Nightcrawler (2014)', '99 Homes (2014)', 'A Most Violent Year (2014)', 'Bill (2015)', 'The Theory of Everything (2014)', 'The Guest (2014)', 'Mandariinid (2013)', 'Relatos salvajes (2014)', 'The Jungle Book (2016)', 'Love &amp; Friendship (2016)', 'Creed (2015)', 'Spy (2015)', \"Tim's Vermeer (2013)\", 'Shelter (2014)', 'Trainwreck (2015)', 'Pride (2014)', 'Fantastic Beasts and Where to Find Them (2016)', 'Slow West (2015)', 'Red Army (2014)', 'Hrútar (2015)', 'Good Kill (2014)', 'Youth (2015)', 'Logan (2017)', 'Still Alice (2014)', 'Berlin Syndrome (2017)', 'A United Kingdom (2016)', 'Sicario (2015)', 'Timbuktu (2014)', 'The End of the Tour (2015)', 'War for the Planet of the Apes (2017)', 'The Lobster (2015)', 'Sing (2016)', \"Maggie's Plan (2015)\", 'Housebound (2014)', 'The Look of Silence (2014)', 'American Made (2017)', '45 Years (2015)', 'La famille Bélier (2014)', 'Whiskey Tango Foxtrot (2016)', 'Captain Fantastic (2016)', 'Turist (2014)', 'The Girl on the Train (2016)', 'Bande de filles (2014)', 'The Salt of the Earth (2014)', 'Bridge of Spies (2015)', 'The BFG (2016)', 'Remember (2015)', 'The Lady in the Van (2015)', 'Le tout nouveau testament (2015)', 'Saul fia (2015)', 'Dope (2015)', 'Baby Driver (2017)', 'Hounds of Love (2016)', 'The Love Witch (2016)', 'The Daughter (2015)', 'Suntan (2016)', 'Urok (2014)', 'Mustang (2015)', 'Okja (2017)', 'Ah-ga-ssi (2016)', 'Manchester by the Sea (2016)', 'Toni Erdmann (2016)', 'Green Room (2015)', 'The LEGO Batman Movie (2017)', 'The Ones Below (2015)', 'Avengers: Infinity War (2018)', 'Free Fire (2016)', 'The Gift (2015)', 'Adult Life Skills (2016)', 'Grandma (2015)', 'Under the Shadow (2016)', 'The Founder (2016)', 'El abrazo de la serpiente (2015)', 'Lady Macbeth (2016)', 'Kubo and the Two Strings (2016)', 'Julieta (2016)', '20th Century Women (2016)', 'Love Is All: 100 Years of Love &amp; Courtship (2014)', 'Ice Guardians (2016)', 'Paddington 2 (2017)', 'Miss Sloane (2016)', 'Nocturnal Animals (2016)', 'Shot Caller (2017)', 'Christine (2016)', 'Loving (2016)', 'The Death of Stalin (2017)', 'Personal Shopper (2016)', \"L'économie du couple (2016)\", 'Hidden Figures (2016)', 'The Age of Shadows (2016)', 'Bacalaureat (2016)', 'Grave (2016)', 'Moonlight (2016)', 'Dunkirk (2017)', 'Three Billboards Outside Ebbing, Missouri (2017)', 'Get Out (2017)', 'Prevenge (2016)', 'I, Daniel Blake (2016)', 'Forushande (2016)', 'Goksung (2016)', 'Aquarius (2016)', 'Toivon tuolla puolen (2017)', 'Paterson (2016)', 'La región salvaje (2016)', 'Umi yori mo mada fukaku (2016)', 'Kimi no na wa. (2016)', 'Logan Lucky (2017)', 'Life (2017)', 'Daphne (2017)', 'The Florida Project (2017)', 'Brawl in Cell Block 99 (2017)', 'Busanhaeng (2016)', 'Call Me by Your Name (2017)', 'I Am Not Your Negro (2016)', 'The Party (2017)', '13th (2016)', 'Professor Marston and the Wonder Women (2017)', 'The Coming War on China (2016)', 'City of Ghosts (2017)', 'Dina (2017)', 'Icarus (2017)', 'Ak-Nyeo (2017)', 'Brian and Charles (2017)']\n",
      "\n",
      "\n",
      "user 8 movies:\n",
      "['Psycho (1960)', 'Night of the Living Dead (1968)', 'Dirty Harry (1971)', 'Jesus Christ Superstar (1973)', 'Monty Python and the Holy Grail (1975)', 'Close Encounters of the Third Kind (1977)', 'Pumping Iron (1977)', 'Damien: Omen II (1978)', 'Cannibal Holocaust (1980)', 'Star Trek: The Motion Picture (1979)', 'The Shining (1980)', 'Creepshow (1982)', 'Christine (1983)', 'A Nightmare on Elm Street (1984)', \"A Nightmare on Elm Street Part 2: Freddy's Revenge (1985)\", 'Heartbreak Ridge (1986)', 'Hellraiser (1987)', 'A Nightmare on Elm Street 3: Dream Warriors (1987)', 'The Princess Bride (1987)', 'RoboCop (1987)', 'Beetle Juice (1988)', \"Child's Play (1988)\", 'The Dead Pool (1988)', 'A Nightmare on Elm Street 4: The Dream Master (1988)', 'Young Guns (1988)', 'Pet Sematary (1989)', 'Goodfellas (1990)', 'Delicatessen (1991)', \"Freddy's Dead: The Final Nightmare (1991)\", 'Sleeping with the Enemy (1991)', 'Candyman (1992)', 'Death Becomes Her (1992)', 'The Muppet Christmas Carol (1992)', 'Reservoir Dogs (1992)', 'Kalifornia (1993)', 'The Adventures of Priscilla, Queen of the Desert (1994)', 'Interview with the Vampire: The Vampire Chronicles (1994)', 'The Mask (1994)', 'Natural Born Killers (1994)', 'Pulp Fiction (1994)', 'Species (1995)', 'Toy Story (1995)', 'The Cable Guy (1996)', 'The Frighteners (1996)', 'Hellraiser: Bloodline (1996)', 'Star Trek: First Contact (1996)', 'Thinner (1996)', 'The Fifth Element (1997)', 'Liar Liar (1997)', 'Fantastic Four (2005)', 'The Prince of Egypt (1998)', 'Star Trek: Insurrection (1998)', 'X-Men (2000)', 'Star Wars: Episode III - Revenge of the Sith (2005)', 'The Road to El Dorado (2000)', \"Charlie's Angels (2000)\", 'Sleepy Hollow (1999)', 'The Lord of the Rings: The Two Towers (2002)', 'How the Grinch Stole Christmas (2000)', 'Bicentennial Man (1999)', 'Monsters, Inc. (2001)', 'You Can Count on Me (2000)', 'Memento (2000)', 'Ginger Snaps (2000)', 'Hannibal (2001)', 'Ghosts of Mars (2001)', 'De reis van Chihiro (2001)', 'Reign of Fire (2002)', 'My Big Fat Greek Wedding (2002)', 'Jeepers Creepers (2001)', 'Kill Bill: Vol. 1 (2003)', 'Rush Hour 2 (2001)', 'Spider (2002)', '28 Days Later... (2002)', 'Koroshiya 1 (2001)', 'Jeepers Creepers II (2003)', 'Cidade de Deus (2002)', 'Elf (2003)', 'Party Monster (2003)', 'Gin gwai (2002)', 'The Animatrix (2003)', 'Haute tension (2003)', 'Hauru no ugoku shiro (2004)', 'Inglourious Basterds (2009)', 'Ju-on (2002)', 'Shaun of the Dead (2004)', 'Mean Girls (2004)', 'Kill Bill: Vol. 2 (2004)', 'Ratatouille (2007)', 'Saw (2004)', 'Tokyo Godfathers (2003)', 'Brokeback Mountain (2005)', 'Super Size Me (2004)', 'Tarnation (2003)', \"The Devil's Rejects (2005)\", 'Sin City (2005)', 'Calvaire (2004)', 'Sweeney Todd: The Demon Barber of Fleet Street (2007)', 'Hard Candy (2005)', 'Resident Evil: Extinction (2007)', 'Fantastic Mr. Fox (2009)', 'Saw II (2005)', 'Scott Pilgrim vs. the World (2010)', 'Sunshine (2007)', 'Little Miss Sunshine (2006)', 'Hostel (2005)', 'The Hills Have Eyes (2006)', 'The Crazies (2010)', 'Severance (2006)', 'The Cottage (2008)', 'Push (2009)', 'There Will Be Blood (2007)', 'Apocalypto (2006)', '4: Rise of the Silver Surfer (2007)', 'Saw III (2006)', 'Jackass Number Two (2006)', 'Hostel: Part II (2007)', 'American Gangster (2007)', 'In Bruges (2008)', 'Dallas Buyers Club (2013)', 'The Hills Have Eyes II (2007)', 'Funny Games U.S. (2007)', 'World War Z (2013)', 'The Darjeeling Limited (2007)', 'The Kids Are All Right (2010)', 'Cloudy with a Chance of Meatballs (2009)', 'The Last House on the Left (2009)', 'The Avengers (2012)', 'The Blind Side (2009)', 'Saw IV (2007)', 'Pineapple Express (2008)', 'WALL·E (2008)', 'Tau ming chong (2007)', \"St. Trinian's (2007)\", 'Hitchcock (2012)', 'Machete (2010)', 'Ghost Town (2008)', 'Up (2009)', 'Repo Men (2010)', 'A Christmas Carol (2009)', 'Eden Log (2007)', 'Jackass 3D (2010)', 'Shutter Island (2010)', 'Saw V (2008)', 'The Final Destination (2009)', 'The Hobbit: The Desolation of Smaug (2013)', 'Bronson (2008)', 'From Paris with Love (2010)', \"The World's End (2013)\", 'Saw VI (2009)', 'RoboCop (2014)', 'This Is the End (2013)', 'Red (2010)', 'The Cabin in the Woods (2011)', 'Hercules (2014)', 'Død snø (2009)', 'Food, Inc. (2008)', 'Iron Man 3 (2013)', 'Burke and Hare (2010)', 'The Great Gatsby (2013)', 'Coriolanus (2011)', 'The Other Guys (2010)', 'The Hunger Games (2012)', 'Prisoners (2013)', 'Star Trek Into Darkness (2013)', 'The Wolverine (2013)', 'Rise of the Guardians (2012)', 'Gravity (2013)', 'Tucker and Dale vs Evil (2010)', 'Saw 7 (2010)', 'Bridesmaids (2011)', 'The Lego Movie (2014)', 'Drive Angry (2011)', 'The Three Musketeers (2011)', 'Captain Phillips (2013)', 'Somos lo que hay (2010)', '30 Minutes or Less (2011)', 'Kick-Ass 2 (2013)', 'The Perks of Being a Wallflower (2012)', 'Now You See Me (2013)', 'Stoker (2013)', \"We're the Millers (2013)\", 'Wreck-It Ralph (2012)', 'Ernest et Célestine (2012)', 'Turbo (2013)', 'X-Men: Days of Future Past (2014)', 'Sinister (2012)', 'Pitch Perfect (2012)', 'Guardians of the Galaxy (2014)', 'Identity Thief (2013)', 'Maniac (2012)', 'West of Memphis (2012)', 'The Grand Budapest Hotel (2014)', 'Muppets Most Wanted (2014)', 'De Hobbit: De Slag van Vijf Legers (2014)', 'The Heat (2013)', 'Bad Grandpa (2013)']\n",
      "\n",
      "\n",
      "user 9 movies:\n",
      "['Octopussy (1983)', 'Trading Places (1983)', \"Ferris Bueller's Day Off (1986)\", 'Christmas Vacation (1989)', 'Road House (1989)', 'Ghost (1990)', 'Edge of Honor (1991)', 'Fargo (1996)', 'Deep Impact (1998)', 'The Bank Job (2008)', 'Sexy Beast (2000)', 'Snatch. (2000)', 'The Pianist (2002)', 'Dawn of the Dead (2004)', 'The Heartbreak Kid (2007)', 'Ant-Man (2015)', 'The Wolf of Wall Street (2013)', 'Eddie the Eagle (2016)', 'Lone Survivor (2013)', '10 Cloverfield Lane (2016)', 'Last Vegas (2013)', 'Jack Ryan: Shadow Recruit (2014)', 'Escape Plan (2013)', 'Hot Tub Time Machine (2010)', 'The Cabin in the Woods (2011)', 'Dead Man Running (2009)', 'Prisoners (2013)', 'Deadpool (2016)', 'Vacation (2015)', 'The Big Short (2015)', 'The Man from U.N.C.L.E. (2015)', 'The Maze Runner (2014)', 'The 33 (2015)', 'Hacksaw Ridge (2016)', 'Bastille Day (2016)', 'Mission: Impossible - Rogue Nation (2015)', 'Arrival (2016)', 'Blackfish (2013)', 'Locke (2013)', 'Fury (2014)', 'Beauty and the Beast (2017)', 'Kingsman: The Secret Service (2014)', 'Furious 7 (2015)', 'Amy (2015)', 'Nightcrawler (2014)', 'The Water Diviner (2014)', 'David Brent: Life on the Road (2016)', 'Sully (2016)', 'Heist (2015)', 'London Has Fallen (2016)', 'The Hateful Eight (2015)', 'The Walk (2015)', 'Mechanic: Resurrection (2016)', 'The Night Before (2015)', 'American Made (2017)', 'Legend (2015)', 'The Martian (2015)', 'Free Fire (2016)', 'The Founder (2016)']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This loads our solution dictionary so you can compare results\n",
    "all_recs_sol = pd.read_pickle(\"data/Term2/recommendations/lesson1/data/all_recs.p\")\n",
    "print('all_recs_sol has {} elements\\n\\n'.format(len(all_recs_sol)))\n",
    "for user, movie in list(all_recs_sol.items())[:5]:\n",
    "    print('user {} movies:\\n{}\\n\\n'.format(user, movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you made it here, you now have recommendations for many users using collaborative filtering!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert all_recs[2] == make_recommendations(2), \\\n",
    "       \"Oops!  Your recommendations for user 2 didn't match ours.\"\n",
    "assert all_recs[26] == make_recommendations(26), \\\n",
    "       \"Oops!  It actually wasn't possible to make any recommendations for user 26.\"\n",
    "assert all_recs[1503] == make_recommendations(1503), \\\n",
    "       \"Oops! Looks like your solution for user 1503 didn't match ours.\"\n",
    "\n",
    "print(\"If you made it here, you now have recommendations for many users using collaborative filtering!\")\n",
    "HTML('<img src=\"images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now What?\n",
    "\n",
    "If you made it this far, you have successfully implemented a solution to making recommendations using collaborative filtering. \n",
    "\n",
    "`8.` Let's do a quick recap of the steps taken to obtain recommendations using collaborative filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your understanding of the results by correctly filling in the dictionary below\n",
    "a = \"pearson's correlation and spearman's correlation\"\n",
    "b = 'item based collaborative filtering'\n",
    "c = \"there were too many ratings to get a stable metric\"\n",
    "d = 'user based collaborative filtering'\n",
    "e = \"euclidean distance and pearson's correlation coefficient\"\n",
    "f = \"manhattan distance and euclidean distance\"\n",
    "g = \"spearman's correlation and euclidean distance\"\n",
    "h = \"the spread in some ratings was zero\"\n",
    "i = 'content based recommendation'\n",
    "\n",
    "sol_dict = {\n",
    "    'The type of recommendation system implemented here was a ...': d,\n",
    "    'The two methods used to estimate user similarity were: ': e,\n",
    "    'There was an issue with using the correlation coefficient.  What was it?': h\n",
    "}\n",
    "\n",
    "t.test_recs(sol_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, let's take a closer look at some of the results.  There are two solution files that you read in to check your results, and you created these objects\n",
    "\n",
    "* **df_dists** - a dataframe of user1, user2, euclidean distance between the two users\n",
    "* **all_recs_sol** - a dictionary of all recommendations (key = user, value = list of recommendations)  \n",
    "\n",
    "`9.` Use these two objects along with the cells below to correctly fill in the dictionary below and complete this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 567\n",
    "b = 1503\n",
    "c = 1319\n",
    "d = 1325\n",
    "e = 2526710    # cf. § \"Why the NaN's?\" above\n",
    "f = 0\n",
    "g = 'Use another method to make recommendations - content based, knowledge based, or model based collaborative filtering'\n",
    "\n",
    "sol_dict2 = {\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using correlation?': e,\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using euclidean distance?': f,\n",
    "    'For how many users were we unable to make any recommendations for using collaborative filtering?': c,\n",
    "    'For how many users were we unable to make 10 recommendations for using collaborative filtering?': d,\n",
    "    'What might be a way for us to get 10 recommendations for every user?': g\n",
    "}\n",
    "\n",
    "t.test_recs2(sol_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cells below for any work you need to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN euclidean distance values\n",
    "df_dists['eucl_dist'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations:  1294\n",
      "Less than 10 recommendations:  17\n"
     ]
    }
   ],
   "source": [
    "# Users without recs and users with less than 10 recs\n",
    "num_no_recs = 0\n",
    "num_less_10_recs = 0\n",
    "\n",
    "for user, movie_recs in all_recs.items():\n",
    "    if len(movie_recs) == 0:\n",
    "        num_no_recs += 1\n",
    "    elif len(movie_recs) < 10:\n",
    "        num_less_10_recs +=1\n",
    "\n",
    "print('No recommendations: ', num_no_recs)    # Found the same value with instructor's code, but not 1319...\n",
    "print('Less than 10 recommendations: ', num_less_10_recs)    # Unlike instructor's solution, I don't count 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
