{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Are We Doing?\n",
    "\n",
    "In the last notebook, you created a working version of SVD for situations even when there are tons of missing values.  This is awesome!  The question now is how well does this solution work?\n",
    "\n",
    "In this notebook, we are going to simulate exactly what we would do in the real world to tune our recommender.  \n",
    "\n",
    "Run the cell below to read in the data and get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>1800's</th>\n",
       "      <th>1900's</th>\n",
       "      <th>2000's</th>\n",
       "      <th>History</th>\n",
       "      <th>News</th>\n",
       "      <th>Horror</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Game-Show</th>\n",
       "      <th>Action</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Short</th>\n",
       "      <th>Western</th>\n",
       "      <th>Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze (1894)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1894</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                          movie              genre  \\\n",
       "0         8  Edison Kinetoscopic Record of a Sneeze (1894)  Documentary|Short   \n",
       "\n",
       "   date  1800's  1900's  2000's  History  News  Horror    ...     Fantasy  \\\n",
       "0  1894       1       0       0        0     0       0    ...           0   \n",
       "\n",
       "   Romance  Game-Show  Action  Documentary  Animation  Comedy  Short  Western  \\\n",
       "0        0          0       0            1          0       0      1        0   \n",
       "\n",
       "   Thriller  \n",
       "0         0  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "      <td>1381620027</td>\n",
       "      <td>2013-10-12 23:20:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
       "0        1     68646      10  1381620027  2013-10-12 23:20:27        0   \n",
       "\n",
       "   month_2  month_3  month_4  month_5    ...      month_9  month_10  month_11  \\\n",
       "0        0        0        0        0    ...            0         1         0   \n",
       "\n",
       "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
       "0         0          1          0          0          0          0          0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the **reviews** dataframe, perform the following tasks to create a training and validation set of data we can use to test the performance of your SVD algorithm using **off-line** validation techniques.\n",
    "\n",
    " * Order the reviews dataframe from earliest to most recent \n",
    " * Pull the first 10000 reviews from  the dataset\n",
    " * Make the first 8000/10000 reviews the training data \n",
    " * Make the last 2000/10000 the test data\n",
    " * Return the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(reviews, order_by, training_size, testing_size):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    reviews - (pandas df) dataframe to split into train and test\n",
    "    order_by - (string) column name to sort by\n",
    "    training_size - (int) number of rows in training set\n",
    "    testing_size - (int) number of rows in the test set\n",
    "    \n",
    "    OUTPUT:\n",
    "    training_df -  (pandas df) dataframe of the training set\n",
    "    validation_df - (pandas df) dataframe of the test set\n",
    "    '''\n",
    "    sorted_reviews = reviews.sort_values(by=order_by, ascending=True)\n",
    "    training_df = sorted_reviews[:training_size]\n",
    "    validation_df = sorted_reviews[training_size:training_size + testing_size]\n",
    "\n",
    "    return training_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to change in this or the next cell\n",
    "# Use our function to create training and test datasets\n",
    "train_df, val_df = create_train_test(reviews, 'date', 8000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the dataframes we are using are the right shape\n",
    "assert train_df.shape[0] == 8000, \"The number of rows doesn't look right in the training dataset.\"\n",
    "assert val_df.shape[0] == 2000, \"The number of rows doesn't look right in the validation dataset\"\n",
    "assert str(train_df.tail(1)['date']).split()[1] == '2013-03-15', \"The last date in the training dataset doesn't look like what we expected.\"\n",
    "assert str(val_df.tail(1)['date']).split()[1] == '2013-03-18', \"The last date in the validation dataset doesn't look like what we expected.\"\n",
    "print(\"Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world, we might have all of the data up to this final date in the training data.  Then we want to see how well we are doing for each of the new ratings, which show up in the test data.\n",
    "\n",
    "Below is a working example of the function created in the previous example you can use (or you can replace with your own).\n",
    "\n",
    "`2.`  Fit the function to the training data with the following hyperparameters: 15 latent features, a learning rate of 0.005, and 250 iterations. This will take some time to run, so you may choose fewer latent features, a higher learning rate, or fewer iteratios if you want to speed up the process.  \n",
    "\n",
    "**Note:** Again, this might be a good time to take a phone call, go for a walk, or just take a little break.  No need to change the code below unless you would like to make changes to reduce the time needed to obtain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=12, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data head() = \n",
      " [[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 10.515413\n",
      "2 \t\t 5.910561\n",
      "3 \t\t 4.121771\n",
      "4 \t\t 3.080157\n",
      "5 \t\t 2.397722\n",
      "6 \t\t 1.916818\n",
      "7 \t\t 1.561167\n",
      "8 \t\t 1.289249\n",
      "9 \t\t 1.076278\n",
      "10 \t\t 0.906407\n",
      "11 \t\t 0.768982\n",
      "12 \t\t 0.656547\n",
      "13 \t\t 0.563710\n",
      "14 \t\t 0.486449\n",
      "15 \t\t 0.421702\n",
      "16 \t\t 0.367092\n",
      "17 \t\t 0.320759\n",
      "18 \t\t 0.281233\n",
      "19 \t\t 0.247344\n",
      "20 \t\t 0.218158\n",
      "21 \t\t 0.192922\n",
      "22 \t\t 0.171022\n",
      "23 \t\t 0.151957\n",
      "24 \t\t 0.135312\n",
      "25 \t\t 0.120743\n",
      "26 \t\t 0.107960\n",
      "27 \t\t 0.096718\n",
      "28 \t\t 0.086812\n",
      "29 \t\t 0.078064\n",
      "30 \t\t 0.070323\n",
      "31 \t\t 0.063461\n",
      "32 \t\t 0.057366\n",
      "33 \t\t 0.051941\n",
      "34 \t\t 0.047104\n",
      "35 \t\t 0.042783\n",
      "36 \t\t 0.038917\n",
      "37 \t\t 0.035450\n",
      "38 \t\t 0.032337\n",
      "39 \t\t 0.029536\n",
      "40 \t\t 0.027013\n",
      "41 \t\t 0.024735\n",
      "42 \t\t 0.022676\n",
      "43 \t\t 0.020812\n",
      "44 \t\t 0.019122\n",
      "45 \t\t 0.017587\n",
      "46 \t\t 0.016192\n",
      "47 \t\t 0.014922\n",
      "48 \t\t 0.013765\n",
      "49 \t\t 0.012708\n",
      "50 \t\t 0.011743\n",
      "51 \t\t 0.010860\n",
      "52 \t\t 0.010051\n",
      "53 \t\t 0.009310\n",
      "54 \t\t 0.008630\n",
      "55 \t\t 0.008005\n",
      "56 \t\t 0.007431\n",
      "57 \t\t 0.006902\n",
      "58 \t\t 0.006415\n",
      "59 \t\t 0.005966\n",
      "60 \t\t 0.005552\n",
      "61 \t\t 0.005170\n",
      "62 \t\t 0.004816\n",
      "63 \t\t 0.004490\n",
      "64 \t\t 0.004187\n",
      "65 \t\t 0.003907\n",
      "66 \t\t 0.003648\n",
      "67 \t\t 0.003407\n",
      "68 \t\t 0.003184\n",
      "69 \t\t 0.002977\n",
      "70 \t\t 0.002784\n",
      "71 \t\t 0.002605\n",
      "72 \t\t 0.002439\n",
      "73 \t\t 0.002284\n",
      "74 \t\t 0.002140\n",
      "75 \t\t 0.002005\n",
      "76 \t\t 0.001880\n",
      "77 \t\t 0.001764\n",
      "78 \t\t 0.001655\n",
      "79 \t\t 0.001553\n",
      "80 \t\t 0.001458\n",
      "81 \t\t 0.001370\n",
      "82 \t\t 0.001287\n",
      "83 \t\t 0.001209\n",
      "84 \t\t 0.001137\n",
      "85 \t\t 0.001069\n",
      "86 \t\t 0.001006\n",
      "87 \t\t 0.000946\n",
      "88 \t\t 0.000891\n",
      "89 \t\t 0.000839\n",
      "90 \t\t 0.000790\n",
      "91 \t\t 0.000744\n",
      "92 \t\t 0.000701\n",
      "93 \t\t 0.000661\n",
      "94 \t\t 0.000623\n",
      "95 \t\t 0.000588\n",
      "96 \t\t 0.000554\n",
      "97 \t\t 0.000523\n",
      "98 \t\t 0.000494\n",
      "99 \t\t 0.000466\n",
      "100 \t\t 0.000440\n",
      "101 \t\t 0.000415\n",
      "102 \t\t 0.000392\n",
      "103 \t\t 0.000371\n",
      "104 \t\t 0.000350\n",
      "105 \t\t 0.000331\n",
      "106 \t\t 0.000313\n",
      "107 \t\t 0.000296\n",
      "108 \t\t 0.000280\n",
      "109 \t\t 0.000265\n",
      "110 \t\t 0.000251\n",
      "111 \t\t 0.000237\n",
      "112 \t\t 0.000225\n",
      "113 \t\t 0.000213\n",
      "114 \t\t 0.000202\n",
      "115 \t\t 0.000191\n",
      "116 \t\t 0.000181\n",
      "117 \t\t 0.000172\n",
      "118 \t\t 0.000163\n",
      "119 \t\t 0.000154\n",
      "120 \t\t 0.000146\n",
      "121 \t\t 0.000139\n",
      "122 \t\t 0.000132\n",
      "123 \t\t 0.000125\n",
      "124 \t\t 0.000118\n",
      "125 \t\t 0.000112\n",
      "126 \t\t 0.000107\n",
      "127 \t\t 0.000101\n",
      "128 \t\t 0.000096\n",
      "129 \t\t 0.000091\n",
      "130 \t\t 0.000087\n",
      "131 \t\t 0.000083\n",
      "132 \t\t 0.000078\n",
      "133 \t\t 0.000075\n",
      "134 \t\t 0.000071\n",
      "135 \t\t 0.000067\n",
      "136 \t\t 0.000064\n",
      "137 \t\t 0.000061\n",
      "138 \t\t 0.000058\n",
      "139 \t\t 0.000055\n",
      "140 \t\t 0.000053\n",
      "141 \t\t 0.000050\n",
      "142 \t\t 0.000048\n",
      "143 \t\t 0.000045\n",
      "144 \t\t 0.000043\n",
      "145 \t\t 0.000041\n",
      "146 \t\t 0.000039\n",
      "147 \t\t 0.000037\n",
      "148 \t\t 0.000036\n",
      "149 \t\t 0.000034\n",
      "150 \t\t 0.000032\n",
      "151 \t\t 0.000031\n",
      "152 \t\t 0.000029\n",
      "153 \t\t 0.000028\n",
      "154 \t\t 0.000027\n",
      "155 \t\t 0.000026\n",
      "156 \t\t 0.000024\n",
      "157 \t\t 0.000023\n",
      "158 \t\t 0.000022\n",
      "159 \t\t 0.000021\n",
      "160 \t\t 0.000020\n",
      "161 \t\t 0.000019\n",
      "162 \t\t 0.000018\n",
      "163 \t\t 0.000018\n",
      "164 \t\t 0.000017\n",
      "165 \t\t 0.000016\n",
      "166 \t\t 0.000015\n",
      "167 \t\t 0.000015\n",
      "168 \t\t 0.000014\n",
      "169 \t\t 0.000013\n",
      "170 \t\t 0.000013\n",
      "171 \t\t 0.000012\n",
      "172 \t\t 0.000012\n",
      "173 \t\t 0.000011\n",
      "174 \t\t 0.000011\n",
      "175 \t\t 0.000010\n",
      "176 \t\t 0.000010\n",
      "177 \t\t 0.000009\n",
      "178 \t\t 0.000009\n",
      "179 \t\t 0.000009\n",
      "180 \t\t 0.000008\n",
      "181 \t\t 0.000008\n",
      "182 \t\t 0.000007\n",
      "183 \t\t 0.000007\n",
      "184 \t\t 0.000007\n",
      "185 \t\t 0.000007\n",
      "186 \t\t 0.000006\n",
      "187 \t\t 0.000006\n",
      "188 \t\t 0.000006\n",
      "189 \t\t 0.000006\n",
      "190 \t\t 0.000005\n",
      "191 \t\t 0.000005\n",
      "192 \t\t 0.000005\n",
      "193 \t\t 0.000005\n",
      "194 \t\t 0.000004\n",
      "195 \t\t 0.000004\n",
      "196 \t\t 0.000004\n",
      "197 \t\t 0.000004\n",
      "198 \t\t 0.000004\n",
      "199 \t\t 0.000004\n",
      "200 \t\t 0.000003\n",
      "201 \t\t 0.000003\n",
      "202 \t\t 0.000003\n",
      "203 \t\t 0.000003\n",
      "204 \t\t 0.000003\n",
      "205 \t\t 0.000003\n",
      "206 \t\t 0.000003\n",
      "207 \t\t 0.000003\n",
      "208 \t\t 0.000002\n",
      "209 \t\t 0.000002\n",
      "210 \t\t 0.000002\n",
      "211 \t\t 0.000002\n",
      "212 \t\t 0.000002\n",
      "213 \t\t 0.000002\n",
      "214 \t\t 0.000002\n",
      "215 \t\t 0.000002\n",
      "216 \t\t 0.000002\n",
      "217 \t\t 0.000002\n",
      "218 \t\t 0.000002\n",
      "219 \t\t 0.000002\n",
      "220 \t\t 0.000001\n",
      "221 \t\t 0.000001\n",
      "222 \t\t 0.000001\n",
      "223 \t\t 0.000001\n",
      "224 \t\t 0.000001\n",
      "225 \t\t 0.000001\n",
      "226 \t\t 0.000001\n",
      "227 \t\t 0.000001\n",
      "228 \t\t 0.000001\n",
      "229 \t\t 0.000001\n",
      "230 \t\t 0.000001\n",
      "231 \t\t 0.000001\n",
      "232 \t\t 0.000001\n",
      "233 \t\t 0.000001\n",
      "234 \t\t 0.000001\n",
      "235 \t\t 0.000001\n",
      "236 \t\t 0.000001\n",
      "237 \t\t 0.000001\n",
      "238 \t\t 0.000001\n",
      "239 \t\t 0.000001\n",
      "240 \t\t 0.000001\n",
      "241 \t\t 0.000001\n",
      "242 \t\t 0.000001\n",
      "243 \t\t 0.000001\n",
      "244 \t\t 0.000001\n",
      "245 \t\t 0.000001\n",
      "246 \t\t 0.000001\n",
      "247 \t\t 0.000000\n",
      "248 \t\t 0.000000\n",
      "249 \t\t 0.000000\n",
      "250 \t\t 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Create user-by-item matrix - nothing to do here\n",
    "train_user_item = train_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "print('Train data head() = \\n', train_data_np[:5])\n",
    "\n",
    "# Fit FunkSVD with the specified hyper parameters to the training data\n",
    "user_mat, movie_mat = FunkSVD(train_data_np, latent_features=15, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the **user_mat** and **movie_mat**, we can use this to make predictions for how users would rate movies, by just computing the dot product of the row associated with a user and the column associated with the movie.\n",
    "\n",
    "`3.` Use the comments in the function below to complete the **predict_rating** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs:\n",
      " [    8    46    48 ..., 53943 53962 53966]\n",
      "\n",
      "In the training data, the row number for user 8 is:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "usr_ids = np.array(train_data_df.index)\n",
    "print('User IDs:\\n', usr_ids)\n",
    "print('\\nIn the training data, the row number for user 8 is:\\n', np.where(usr_ids == 8)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_matrix, movie_matrix, user_id, movie_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_matrix - user by latent factor matrix\n",
    "    movie_matrix - latent factor by movie matrix\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    \n",
    "    OUTPUT:\n",
    "    pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "    '''\n",
    "    # Use the training data to create 2 series of User IDs and Movie IDs that match the ordering in the training data\n",
    "    user_ids_series =  np.array(train_data_df.index)\n",
    "    movie_ids_series = np.array(train_data_df.columns)\n",
    "    \n",
    "    # User the row and Movie column\n",
    "    user_row =  np.where(user_ids_series == user_id)[0][0]\n",
    "    movie_col = np.where(movie_ids_series == movie_id)[0][0]\n",
    "    \n",
    "    # Take dot product of that row and column in U and V to make prediction\n",
    "    pred = np.dot(user_matrix[user_row, :], movie_matrix[:, movie_col])\n",
    "   \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.966375659700871"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with the first user-movie in the user-movie matrix (notice this is a nan)\n",
    "pred_val = predict_rating(user_mat, movie_mat, 8, 2844)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great that you now have a way to make predictions. However it might be nice to get a little phrase back about the user, movie, and rating.\n",
    "\n",
    "`4.` Use the comments in the function below to complete the **predict_rating** function.  \n",
    "\n",
    "**Note:** The movie name doesn't come back in a great format, so you can see in the solution I messed around with it a bit just to make it a little nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction_summary(user_id, movie_id, prediction):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according to the movies df\n",
    "    prediction - the predicted rating for user_id-movie_id\n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints a statement about the user, movie, and prediction made\n",
    "    \n",
    "    '''\n",
    "    movie_name = movies[movies['movie_id'] == movie_id]['movie']\n",
    "    print('The predicted rating from User {} for Movie \"{}\" is {}.'.format(\n",
    "        user_id, list(movie_name)[0], round(prediction, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating from User 8 for Movie \"Fantômas - À l'ombre de la guillotine (1913)\" is 6.97.\n"
     ]
    }
   ],
   "source": [
    "# Test your function the the results of the previous function\n",
    "print_prediction_summary(8, 2844, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the ability to make predictions, let's see how well our predictions do on the test ratings we already have.  This will give an indication of how well we have captured the latent features, and our ability to use the latent features to make predictions in the future!\n",
    "\n",
    "`5.` For each of the user-movie rating in the **val_df** dataset, compare the actual rating given to the prediction you would make.  How do your predictions do?  Do you run into any problems?  If yes, what is the problem?  Use the document strings and comments below to assist as you work through these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1598822,  289879, 1563738, 1458175,  103639])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_val_df = val_df[:5]\n",
    "np.array(sub_val_df['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 49056 / Movie 1598822: actual rating = 8 and predicted rating = 5.8164529793651205\n",
      "\n",
      "User 49056 / Movie 289879: actual rating = 9 and predicted rating = 8.24848605267088\n",
      "\n",
      "User 49056 / Movie 1563738: actual rating = 9 and predicted rating = 7.131181390132628\n",
      "\n",
      "User 49056 / Movie 1458175: actual rating = 4 and predicted rating = 7.952979286656407\n",
      "\n",
      "User 28599 / Movie 103639: actual rating = 8 and predicted rating = 8.276202322972312\n",
      "\n",
      "User 50593 / Movie 1560985: actual rating = 4 and predicted rating = 2.4559316372281064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validation_comparison(val_df, num_preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    val_df - the validation dataset created in the third cell above\n",
    "    num_preds - (int) the number of rows (going in order) you would like to make predictions for\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing returned - print a statement about the prediciton made for each row of val_df from row 0 to num_preds\n",
    "    '''\n",
    "    user_ids, movie_ids = np.array(val_df[:num_preds]['user_id']), np.array(val_df[:num_preds]['movie_id'])\n",
    "    \n",
    "    for user_id, movie_id in zip(user_ids, movie_ids):\n",
    "        actual_rating = list(val_df[(val_df['user_id'] == user_id) & (val_df['movie_id'] == movie_id)]['rating'])[0]\n",
    "        pred_rating = predict_rating(user_mat, movie_mat, user_id, movie_id)\n",
    "        print('User {} / Movie {}: actual rating = {} and predicted rating = {}\\n'.format(\n",
    "            user_id, movie_id, actual_rating, pred_rating))\n",
    "        \n",
    "# Perform the predicted vs. actual for the first 6 rows.  How does it look?\n",
    "validation_comparison(val_df, 6)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The instructor's code is cleaner:**\n",
    "```\n",
    "val_users = np.array(val_df['user_id'])\n",
    "val_movies = np.array(val_df['movie_id'])\n",
    "val_ratings = np.array(val_df['rating'])\n",
    "    \n",
    "for idx in range(num_preds):\n",
    "    pred = predict_rating(user_mat, movie_mat, val_users[idx], val_movies[idx])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 49056 / Movie 1598822: actual rating = 8 and predicted rating = 5.8164529793651205\n",
      "\n",
      "User 49056 / Movie 289879: actual rating = 9 and predicted rating = 8.24848605267088\n",
      "\n",
      "User 49056 / Movie 1563738: actual rating = 9 and predicted rating = 7.131181390132628\n",
      "\n",
      "User 49056 / Movie 1458175: actual rating = 4 and predicted rating = 7.952979286656407\n",
      "\n",
      "User 28599 / Movie 103639: actual rating = 8 and predicted rating = 8.276202322972312\n",
      "\n",
      "User 50593 / Movie 1560985: actual rating = 4 and predicted rating = 2.4559316372281064\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-70188ffbf3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the predicted vs. actual for the first 7 rows.  What happened?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-530a02642ff1>\u001b[0m in \u001b[0;36mvalidation_comparison\u001b[0;34m(val_df, num_preds)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mactual_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpred_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         print('User {} / Movie {}: actual rating = {} and predicted rating = {}\\n'.format(\n\u001b[1;32m     16\u001b[0m             user_id, movie_id, actual_rating, pred_rating))\n",
      "\u001b[0;32m<ipython-input-18-d10a322cea62>\u001b[0m in \u001b[0;36mpredict_rating\u001b[0;34m(user_matrix, movie_matrix, user_id, movie_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# User the row and Movie column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0muser_row\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids_series\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmovie_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ids_series\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Take dot product of that row and column in U and V to make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Perform the predicted vs. actual for the first 7 rows.  What happened?\n",
    "validation_comparison(val_df, 7)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A statement about why you think what happened happened.**\n",
    "\n",
    "The **Cold Start** problem: the validation set contains users and movies that didn't exist in the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
